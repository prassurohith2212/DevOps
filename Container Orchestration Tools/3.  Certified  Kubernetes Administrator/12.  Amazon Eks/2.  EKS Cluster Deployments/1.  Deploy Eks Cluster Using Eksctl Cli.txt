
1.Deploy EKS Cluster Using Ekctl:
==================================

Step 1 : Introduction
========================

1. Understand about EKS Core Objects
 - Control Plane
 - Worker Nodes & Node Groups
 - Fargate Profiles
 - VPC

2. Create EKS Cluster

3. Associate EKS Cluster to IAM OIDC Provider

4. Create EKS Node Groups

5. Verify Cluster, Node Groups, EC2 Instances, IAM Policies and Node Groups.



Step 2: Create EKS Cluster using Eksctl :
=========================================

1. It will take 15 to 20 minutes to create the Cluster Control Plane.

2.Create Eks Cluster.

# eksctl create cluster --name=eksdemo1 --region=us-east-1 --zones=us-east-1a,us-east-1b --without-nodegroup 

3.Get List of clusters

# eksctl get cluster 



Step 3: Create & Associate IAM OIDC Provider for our EKS Cluster.
=================================================================

1. To enable and use AWS IAM roles for Kubernetes service accounts on our EKS cluster, we must create & associate OIDC identity provider.
2. To do so using eksctl we can use the below command.
3. Use latest eksctl version (as on today the latest version is 0.21.0)

4. # Template

# eksctl utils associate-iam-oidc-provider --region region-code --cluster <cluter-name> --approve

5. Replace with region & cluster name

# eksctl utils associate-iam-oidc-provider --region us-east-1 --cluster eksdemo1  --approve



Step 4: Create EC2 Keypair:
===============================

1. Create a new EC2 Keypair with name as kube-demo
2. This keypair we will use it when creating the EKS NodeGroup.
3. This will help us to login to the EKS Worker Nodes using Terminal.



Step 5: Create Node Group with additional Add-Ons in Public Subnets.
=======================================================================

1. These add-ons will create the respective IAM policies for us automatically within our Node Group role.

2. Create Public Node Group   

# eksctl create nodegroup --cluster=eksdemo1 \
                       --region=us-east-1 \
                       --name=eksdemo1-ng-public1 \
                       --node-type=t3.medium \
                       --nodes=2 \
                       --nodes-min=2 \
                       --nodes-max=4 \
                       --node-volume-size=20 \
                       --ssh-access \
                       --ssh-public-key=kube-demo \
                       --managed \
                       --asg-access \
                       --external-dns-access \
                       --full-ecr-access \
                       --appmesh-access \
                       --alb-ingress-access 



Step 6 Verify Cluster & Nodes
===============================
Verify NodeGroup subnets to confirm EC2 Instances are in Public Subnet.
-------------------------------------------------------------------------

1. Verify the node group subnet to ensure it created in public subnets.
---------------------------------------------------------------------------
 - Go to Services -> EKS -> eksdemo -> eksdemo1-ng1-public
 - Click on Associated subnet in Details tab
 - Click on Route Table Tab. 
 - We should see that internet route via Internet Gateway (0.0.0.0/0 -> igw-xxxxxxxx)


2. Verify Cluster, NodeGroup in EKS Management Console:
---------------------------------------------------------

# Go to Services -> Elastic Kubernetes Service -> eksdemo1


3. List Worker Nodes
---------------------

- List EKS clusters
# eksctl get cluster

- List NodeGroups in a cluster
# eksctl get nodegroup --cluster=<clusterName>

- List Nodes in current kubernetes cluster
# kubectl get nodes -o wide

- Our kubectl context should be automatically changed to new cluster
# kubectl config view --minify


4. Verify Worker Node IAM Role and list of Policies
----------------------------------------------------
# Go to Services -> EC2 -> Worker Nodes
# Click on IAM Role associated to EC2 Worker Nodes


5. Verify Security Group Associated to Worker Nodes.
--------------------------------------------------------
# Go to Services -> EC2 -> Worker Nodes
# Click on Security Group associated to EC2 Instance which contains remote in the name.


6. Verify CloudFormation Stacks.
--------------------------------------
# Verify Control Plane Stack & Events
# Verify NodeGroup Stack & Events


7. Login to Worker Node using Keypai kube-demo
-----------------------------------------------

1. Login to worker node

- For MAC or Linux or Windows10
# ssh -i kube-demo.pem ec2-user@<Public-IP-of-Worker-Node>

- For Windows 7
# Use putty



Step 7: Update Worker Nodes Security Group to allow all traffic.
==================================================================

- We need to allow All Traffic on worker node security group.

